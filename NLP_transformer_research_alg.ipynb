{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets rouge"
      ],
      "metadata": {
        "id": "68oaLT_Y-8mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer, \\\n",
        "    AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, \\\n",
        "    AutoModelForQuestionAnswering, AutoModelForTokenClassification\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "from datasets import load_dataset\n",
        "from rouge import Rouge\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "import pandas as pd\n",
        "import yaml\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "o288Rue_VQ1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Образец yaml-конфигурации\n",
        "\n",
        "\"\"\"\n",
        "device: cpu\n",
        "model_name: cointegrated/rubert-tiny2\n",
        "model_type: classification\n",
        "num_labels: 5\n",
        "max_length: 512\n",
        "stride: 128\n",
        "batch_size: 8\n",
        "learning_rate: 2e-5\n",
        "num_epochs: 3\n",
        "scheduler_step_size: 1\n",
        "grad_accumulation_steps: 4\n",
        "eval_every: 500\n",
        "early_stopping_patience: 3\n",
        "save_best_model: true\n",
        "\n",
        "tasks:\n",
        "  sentiment_analysis:\n",
        "    dataset_name: MonoHime/ru_sentiment_dataset\n",
        "    subset_name: default\n",
        "    text_column: text\n",
        "    label_column: sentiment\n",
        "    metrics: [accuracy, f1_macro]\n",
        "  classification:\n",
        "    dataset_name: ag_news\n",
        "    subset_name: default\n",
        "    text_column: text\n",
        "    label_column: label\n",
        "    metrics: [accuracy, f1_macro]\n",
        "  ner:\n",
        "    dataset_name: iluvvatar/NEREL\n",
        "    subset_name: data\n",
        "    text_column: text\n",
        "    label_column: entities\n",
        "    metrics: [precision, recall, f1]\n",
        "  summarization:\n",
        "    dataset_name: zjkarina/matreshka\n",
        "    subset_name: default\n",
        "    input_columns: [role, dialog, persona]\n",
        "    summary_column: summary\n",
        "    metrics: [rouge, bleu]\n",
        "  question_answering:\n",
        "    dataset_name: RussianNLP/russian_super_glue\n",
        "    subset_name: rucos\n",
        "    input_columns: passage\n",
        "    question_column: question\n",
        "    metrics: [exact_match, f1]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "RVQEwp4CXNpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение датасета\n",
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, datasets, task_to_datakey):\n",
        "        self.datasets = datasets\n",
        "        self.task_to_datakey = task_to_datakey\n",
        "\n",
        "    def __len__(self):\n",
        "        return sum(len(dataset) for dataset in self.datasets.values())\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        task = self.task_to_datakey[idx]\n",
        "        datakey = self.task_to_datakey[task]\n",
        "        return self.datasets[task][datakey[idx]]"
      ],
      "metadata": {
        "id": "vhrxHpIDY-SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbrtBuHuLbFP"
      },
      "outputs": [],
      "source": [
        "# Загрузка конфигурации\n",
        "with open('config.yaml', 'r') as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Загрузка датасетов\n",
        "datasets = {}\n",
        "for task, task_config in config['tasks'].items():\n",
        "    dataset = load_dataset(task_config['dataset_name'],\n",
        "                           task_config['subset_name'])\n",
        "    datasets[task] = dataset\n",
        "\n",
        "# Токенизация\n",
        "tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
        "\n",
        "def preprocess_function(examples, task_config):\n",
        "    # Препроцессинг в зависимости от задачи\n",
        "    if task == 'classification':\n",
        "        return tokenizer(examples[task_config['text_column']], truncation=True)\n",
        "\n",
        "    elif task == 'summarization':\n",
        "        # Объединение нескольких колонок входных данных в одну строку\n",
        "        input_text = [' '.join([examples[col][i] for col in task_config['input_columns']])\n",
        "                      for i in range(len(examples[task_config['input_columns'][0]]))]\n",
        "        return tokenizer(input_text,\n",
        "                         examples[task_config['summary_column']],\n",
        "                         truncation=True)\n",
        "\n",
        "    elif task == 'ner':\n",
        "        tokenized_examples = tokenizer(\n",
        "            examples[task_config['text_column']],\n",
        "            truncation=True,\n",
        "            is_split_into_words=True\n",
        "            )\n",
        "        labels = []\n",
        "        for i, label in enumerate(examples[task_config['label_column']]):\n",
        "            word_ids = tokenized_examples.word_ids(batch_index=i)\n",
        "            label_ids = []\n",
        "            for word_id in word_ids:\n",
        "                if word_id is None:\n",
        "                    label_ids.append(-100)\n",
        "                else:\n",
        "                    label_ids.append(label[word_id])\n",
        "            labels.append(label_ids)\n",
        "        tokenized_examples['labels'] = labels\n",
        "        return tokenized_examples\n",
        "\n",
        "    elif task == 'question_answering':\n",
        "        # Объединение нескольких колонок входных данных в одну строку\n",
        "        input_text = [' '.join([examples[col][i] for col in task_config['input_columns']])\n",
        "                      for i in range(len(examples[task_config['input_columns'][0]]))]\n",
        "        return tokenizer(\n",
        "            examples[task_config['question_column']],\n",
        "            input_text,\n",
        "            truncation='only_second',\n",
        "            max_length=task_config['max_length'],\n",
        "            stride=task_config['stride'],\n",
        "            return_overflowing_tokens=True,\n",
        "            return_offsets_mapping=True,\n",
        "            padding='max_length'\n",
        "            )\n",
        "\n",
        "    elif task == 'sentiment_analysis':\n",
        "        return tokenizer(examples[task_config['text_column']],\n",
        "                         truncation=True,\n",
        "                         max_length=config['max_length'],\n",
        "                         padding='max_length')\n",
        "\n",
        "tokenized_datasets = {}\n",
        "for task, dataset in datasets.items():\n",
        "    task_config = config['tasks'][task]\n",
        "    tokenized_datasets[task] = dataset.map(\n",
        "        lambda examples: preprocess_function(examples, task_config),\n",
        "        batched=True,\n",
        "        # remove_columns=dataset.column_names\n",
        "    )\n",
        "\n",
        "# Создание даталоадера\n",
        "task_to_datakey = {\n",
        "    task: list(dataset['train'].keys()) for task, dataset in tokenized_datasets.items()\n",
        "    }\n",
        "train_dataset = MultiTaskDataset(tokenized_datasets,\n",
        "                                 task_to_datakey)\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size=config['batch_size'],\n",
        "                              shuffle=True)\n",
        "\n",
        "# Загрузка предобученной модели\n",
        "if config['model_type'] == 'classification':\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        config['model_name'], num_labels=config['num_labels']\n",
        "        )\n",
        "elif config['model_type'] == 'summarization':\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(config['model_name'])\n",
        "elif config['model_type'] == 'question_answering':\n",
        "    model = AutoModelForQuestionAnswering.from_pretrained(config['model_name'])\n",
        "elif config['model_type'] == 'ner':\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        config['model_name'], num_labels=config['num_labels']\n",
        "    )\n",
        "elif config['model_type'] == 'sentiment_analysis':\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        config['model_name'], num_labels=config['num_labels']\n",
        "    )\n",
        "else:\n",
        "    print(\"Use only params in 'model_type': classification/summarization/question_answering/ner/sentiment_analysis\")\n",
        "    exit()\n",
        "\n",
        "# Оптимизатор и планировщик\n",
        "optimizer = optim.AdamW(model.parameters(),\n",
        "                        lr=config['learning_rate'])\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
        "                                      step_size=config['scheduler_step_size'])\n",
        "\n",
        "# Инициализация объекта Rouge\n",
        "rouge = Rouge()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Цикл обучения\n",
        "results = []\n",
        "\n",
        "for epoch in range(config['num_epochs']):\n",
        "\n",
        "    train_pbar = tqdm(\n",
        "        train_dataloader,\n",
        "        desc=f\"Epoch {epoch + 1} [Training]\",\n",
        "        position=0,\n",
        "        leave=True\n",
        "    )\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input_ids = batch['input_ids'].to(config['device'])\n",
        "        attention_mask = batch['attention_mask'].to(config['device'])\n",
        "        labels = batch['labels'].to(config['device'])\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        train_pbar.update(1)\n",
        "        train_pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    # Оценка на валидации\n",
        "    val_scores = {}\n",
        "    for task, dataset in tokenized_datasets.items():\n",
        "        if 'validation' in dataset:\n",
        "            if task == 'classification':\n",
        "                val_preds = []\n",
        "                val_labels = []\n",
        "                for batch in DataLoader(dataset['validation'],\n",
        "                                        batch_size=config['batch_size']):\n",
        "                    input_ids = batch['input_ids'].to(config['device'])\n",
        "                    attention_mask = batch['attention_mask'].to(config['device'])\n",
        "                    labels = batch['labels'].to(config['device'])\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(input_ids,\n",
        "                                        attention_mask=attention_mask)\n",
        "\n",
        "                    preds = torch.argmax(outputs.logits, dim=-1)\n",
        "                    val_preds.extend(preds.tolist())\n",
        "                    val_labels.extend(labels.tolist())\n",
        "\n",
        "                accuracy = accuracy_score(val_labels, val_preds)\n",
        "                f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "                val_scores[f'{task}_accuracy'] = accuracy\n",
        "                val_scores[f'{task}_f1'] = f1\n",
        "\n",
        "            elif task == 'summarization':\n",
        "                val_preds = []\n",
        "                val_labels = []\n",
        "                for batch in DataLoader(\n",
        "                    dataset['validation'], batch_size=config['batch_size']\n",
        "                    ):\n",
        "                    input_ids = batch['input_ids'].to(config['device'])\n",
        "                    attention_mask = batch['attention_mask'].to(config['device'])\n",
        "                    labels = batch['labels'].to(config['device'])\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model.generate(\n",
        "                            input_ids,\n",
        "                            attention_mask=attention_mask\n",
        "                            )\n",
        "\n",
        "                    preds = tokenizer.batch_decode(\n",
        "                        outputs, skip_special_tokens=True\n",
        "                        )\n",
        "                    labels = tokenizer.batch_decode(\n",
        "                        labels, skip_special_tokens=True\n",
        "                        )\n",
        "                    val_preds.extend(preds)\n",
        "                    val_labels.extend(labels)\n",
        "\n",
        "                # Вычисление метрик ROUGE\n",
        "                rouge_scores = rouge.get_scores(\n",
        "                    val_preds, val_labels, avg=True\n",
        "                    )\n",
        "                rouge_1 = rouge_scores['rouge-1']['f']\n",
        "                rouge_2 = rouge_scores['rouge-2']['f']\n",
        "                rouge_l = rouge_scores['rouge-l']['f']\n",
        "\n",
        "                val_scores[f'{task}_rouge_1'] = rouge_1\n",
        "                val_scores[f'{task}_rouge_2'] = rouge_2\n",
        "                val_scores[f'{task}_rouge_l'] = rouge_l\n",
        "\n",
        "                # Вычисление метрики BLEU\n",
        "                bleu_scores = corpus_bleu(\n",
        "                    [[ref] for ref in val_labels], val_preds\n",
        "                    )\n",
        "                val_scores[f'{task}_bleu'] = bleu_scores\n",
        "\n",
        "            elif task == 'ner':\n",
        "                val_preds = []\n",
        "                val_labels = []\n",
        "                for batch in DataLoader(dataset['validation'], batch_size=config['batch_size']):\n",
        "                    input_ids = batch['input_ids'].to(config['device'])\n",
        "                    attention_mask = batch['attention_mask'].to(config['device'])\n",
        "                    labels = batch['labels'].to(config['device'])\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "                    preds = torch.argmax(outputs.logits, dim=-1)\n",
        "                    val_preds.extend(preds[attention_mask.bool()].tolist())\n",
        "                    val_labels.extend(labels[attention_mask.bool()].tolist())\n",
        "\n",
        "                val_preds = [model.config.id2label[pred] for pred in val_preds]\n",
        "                val_labels = [model.config.id2label[label] for label in val_labels]\n",
        "\n",
        "                precision = precision_score(val_labels, val_preds, average='micro')\n",
        "                recall = recall_score(val_labels, val_preds, average='micro')\n",
        "                f1 = f1_score(val_labels, val_preds, average='micro')\n",
        "                val_scores[f'{task}_precision'] = precision\n",
        "                val_scores[f'{task}_recall'] = recall\n",
        "                val_scores[f'{task}_f1'] = f1\n",
        "\n",
        "            elif task == 'sentiment_analysis':\n",
        "                val_preds = []\n",
        "                val_labels = []\n",
        "                for batch in DataLoader(dataset['validation'], batch_size=config['batch_size']):\n",
        "                    input_ids = batch['input_ids'].to(config['device'])\n",
        "                    attention_mask = batch['attention_mask'].to(config['device'])\n",
        "                    labels = batch['labels'].to(config['device'])\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "                    preds = torch.argmax(outputs.logits, dim=-1)\n",
        "                    val_preds.extend(preds.tolist())\n",
        "                    val_labels.extend(labels.tolist())\n",
        "\n",
        "                accuracy = accuracy_score(val_labels, val_preds)\n",
        "                f1 = f1_score(val_labels, val_preds, average='macro')\n",
        "                val_scores[f'{task}_accuracy'] = accuracy\n",
        "                val_scores[f'{task}_f1'] = f1\n",
        "\n",
        "            elif task == 'question_answering':\n",
        "                val_preds = []\n",
        "                val_labels = []\n",
        "                for batch in DataLoader(dataset['validation'], batch_size=config['batch_size']):\n",
        "                    input_ids = batch['input_ids'].to(config['device'])\n",
        "                    attention_mask = batch['attention_mask'].to(config['device'])\n",
        "                    start_positions = batch['start_positions'].to(config['device'])\n",
        "                    end_positions = batch['end_positions'].to(config['device'])\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Сохранение результатов\n",
        "        results.append({'epoch': epoch, 'loss': loss.item(), **val_scores})\n",
        "        print(\n",
        "            f\"Epoch {epoch+1}/{config['num_epochs']}, Loss: {loss.item()}, Validation Scores: {val_scores}\"\n",
        "            )\n",
        "\n",
        "    # Сохранение результатов в CSV\n",
        "    results_df = pd.DataFrame(results)\n",
        "    results_df.to_csv('results.csv', index=False)\n",
        "\n",
        "    # Сохранение лучшей модели\n",
        "    best_model_path = f\"best_model_{config['model_name']}.pth\"\n",
        "    torch.save(model.state_dict(), best_model_path)"
      ],
      "metadata": {
        "id": "GkH_Gb7fXAHT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}